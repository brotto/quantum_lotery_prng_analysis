#!/usr/bin/env python3
"""
Analisador Avan√ßado de Padr√µes
Implementa t√©cnicas sofisticadas para descoberta de seed
"""

import numpy as np
import pandas as pd
from scipy import signal, stats
from scipy.fft import fft, fftfreq
import matplotlib.pyplot as plt
from datetime import datetime
import json

class AdvancedPatternAnalyzer:
    def __init__(self, engine):
        self.engine = engine
        self.analysis_results = {}
        
    def analyze_temporal_patterns(self):
        """An√°lise de padr√µes temporais nos dados"""
        print("\nüìà Analisando padr√µes temporais...")
        
        if not self.engine.data_loaded:
            return None
        
        # Extrair s√©rie temporal de m√©dias
        time_series = []
        for draw_info in self.engine.historical_data:
            mean_value = np.mean(draw_info['numbers'])
            time_series.append(mean_value)
        
        time_series = np.array(time_series)
        
        # 1. An√°lise de Fourier
        fft_values = fft(time_series)
        frequencies = fftfreq(len(time_series))
        
        # Encontrar frequ√™ncias dominantes
        power_spectrum = np.abs(fft_values) ** 2
        dominant_freq_idx = np.argsort(power_spectrum)[-10:]
        
        # 2. Detec√ß√£o de pontos de mudan√ßa
        change_points = self.detect_change_points(time_series)
        
        # 3. An√°lise de autocorrela√ß√£o
        autocorr = signal.correlate(time_series, time_series, mode='full')
        autocorr = autocorr[len(autocorr)//2:]
        autocorr /= autocorr[0]
        
        # Encontrar picos de autocorrela√ß√£o
        peaks, _ = signal.find_peaks(autocorr, height=0.5)
        
        self.analysis_results['temporal'] = {
            'dominant_frequencies': frequencies[dominant_freq_idx].tolist(),
            'change_points': change_points,
            'autocorr_peaks': peaks.tolist(),
            'mean_series': time_series.tolist()
        }
        
        print(f"   ‚úì {len(change_points)} pontos de mudan√ßa detectados")
        print(f"   ‚úì {len(peaks)} picos de autocorrela√ß√£o encontrados")
        
        return self.analysis_results['temporal']
    
    def detect_change_points(self, series):
        """Detec√ß√£o avan√ßada de pontos de mudan√ßa"""
        from scipy.stats import ttest_ind
        
        window_size = 50
        change_points = []
        
        for i in range(window_size, len(series) - window_size, 10):
            # Teste t entre janelas antes e depois
            before = series[i-window_size:i]
            after = series[i:i+window_size]
            
            _, p_value = ttest_ind(before, after)
            
            if p_value < 0.01:  # Mudan√ßa significativa
                change_points.append(i)
        
        # Consolidar pontos pr√≥ximos
        consolidated = []
        for cp in change_points:
            if not consolidated or cp - consolidated[-1] > 20:
                consolidated.append(cp)
        
        return consolidated
    
    def analyze_number_transitions(self):
        """Analisa transi√ß√µes entre n√∫meros consecutivos"""
        print("\nüîÑ Analisando transi√ß√µes de n√∫meros...")
        
        if not self.engine.data_loaded:
            return None
        
        # Matriz de transi√ß√£o
        transition_matrix = np.zeros((60, 60))
        
        for i in range(len(self.engine.historical_data) - 1):
            current = self.engine.historical_data[i]['numbers']
            next_draw = self.engine.historical_data[i + 1]['numbers']
            
            # Contar transi√ß√µes
            for num1 in current:
                for num2 in next_draw:
                    transition_matrix[num1-1, num2-1] += 1
        
        # Normalizar
        row_sums = transition_matrix.sum(axis=1)
        transition_matrix = transition_matrix / (row_sums[:, np.newaxis] + 1e-10)
        
        # Encontrar padr√µes an√¥malos
        anomalies = []
        threshold = np.mean(transition_matrix) + 2 * np.std(transition_matrix)
        
        for i in range(60):
            for j in range(60):
                if transition_matrix[i, j] > threshold:
                    anomalies.append({
                        'from': i + 1,
                        'to': j + 1,
                        'probability': float(transition_matrix[i, j])
                    })
        
        self.analysis_results['transitions'] = {
            'matrix': transition_matrix.tolist(),
            'anomalies': anomalies,
            'max_transition': float(np.max(transition_matrix)),
            'mean_transition': float(np.mean(transition_matrix))
        }
        
        print(f"   ‚úì {len(anomalies)} transi√ß√µes an√¥malas detectadas")
        
        return self.analysis_results['transitions']
    
    def find_seed_signature(self, candidates):
        """Encontra assinatura √∫nica do seed correto"""
        print("\nüîê Buscando assinatura do seed...")
        
        signatures = []
        
        for candidate in candidates[:10]:  # Top 10 candidatos
            seed = candidate['seed']
            c = candidate['c']
            
            # Gerar sequ√™ncia teste
            test_length = 100
            current_state = seed
            sequence = []
            
            for _ in range(test_length):
                draw = self.engine.state_to_lottery_numbers(current_state, c)
                if draw:
                    sequence.append(draw)
                    for _ in range(6):
                        current_state = self.engine.lcg_next(current_state, c)
            
            if len(sequence) < test_length / 2:
                continue
            
            # Calcular caracter√≠sticas √∫nicas
            signature = {
                'seed': seed,
                'c': c,
                'features': {}
            }
            
            # 1. Distribui√ß√£o de frequ√™ncias
            freq_dist = np.zeros(60)
            for draw in sequence:
                for num in draw:
                    freq_dist[num-1] += 1
            
            signature['features']['freq_entropy'] = stats.entropy(freq_dist)
            signature['features']['freq_std'] = float(np.std(freq_dist))
            
            # 2. Padr√£o de gaps
            gaps = []
            for num in range(1, 61):
                appearances = [i for i, draw in enumerate(sequence) if num in draw]
                if len(appearances) > 1:
                    num_gaps = [appearances[i+1] - appearances[i] 
                               for i in range(len(appearances)-1)]
                    gaps.extend(num_gaps)
            
            if gaps:
                signature['features']['mean_gap'] = float(np.mean(gaps))
                signature['features']['gap_variance'] = float(np.var(gaps))
            
            # 3. Correla√ß√£o m√©dia
            correlations = []
            for i in range(len(sequence) - 1):
                corr = self.engine.calculate_correlation(sequence[i], sequence[i+1])
                correlations.append(corr)
            
            signature['features']['mean_correlation'] = float(np.mean(correlations))
            signature['features']['corr_stability'] = float(np.std(correlations))
            
            # Calcular score de proximidade com padr√£o esperado
            target_corr_diff = abs(signature['features']['mean_correlation'] - 0.754)
            signature['match_score'] = 1 / (1 + target_corr_diff)
            
            signatures.append(signature)
        
        # Ordenar por match_score
        signatures.sort(key=lambda x: x['match_score'], reverse=True)
        
        self.analysis_results['signatures'] = signatures
        
        if signatures:
            best = signatures[0]
            print(f"   ‚úì Melhor assinatura encontrada:")
            print(f"     Seed: {best['seed']}, c: {best['c']}")
            print(f"     Correla√ß√£o m√©dia: {best['features']['mean_correlation']:.3f}")
            print(f"     Score de match: {best['match_score']:.3f}")
        
        return signatures
    
    def generate_validation_report(self, best_candidate):
        """Gera relat√≥rio detalhado de valida√ß√£o"""
        print("\nüìã Gerando relat√≥rio de valida√ß√£o...")
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'best_candidate': best_candidate,
            'analysis_summary': self.analysis_results,
            'validation_metrics': {}
        }
        
        # Valida√ß√£o extensa
        seed = best_candidate['seed']
        c = best_candidate['c']
        
        # 1. Teste de correla√ß√£o em toda a sequ√™ncia
        print("   Testando correla√ß√£o completa...")
        full_validation = self.engine.validate_recent_draws(seed, c, 
                                                          len(self.engine.historical_data))
        report['validation_metrics']['full_sequence'] = full_validation
        
        # 2. Teste por per√≠odos
        periods = [100, 500, 1000]
        for period in periods:
            if period < len(self.engine.historical_data):
                validation = self.engine.validate_recent_draws(seed, c, period)
                report['validation_metrics'][f'last_{period}'] = validation
        
        # 3. Previs√µes futuras
        predictions = self.engine.generate_predictions(seed, c, 20)
        report['future_predictions'] = predictions
        
        # Salvar relat√≥rio
        report_path = f"../output/validation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2, default=str)
        
        print(f"   ‚úì Relat√≥rio salvo em: {report_path}")
        
        return report
    
    def visualize_analysis(self):
        """Cria visualiza√ß√µes dos padr√µes encontrados"""
        print("\nüìä Gerando visualiza√ß√µes...")
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # 1. S√©rie temporal com pontos de mudan√ßa
        ax1 = axes[0, 0]
        if 'temporal' in self.analysis_results:
            temporal = self.analysis_results['temporal']
            ax1.plot(temporal['mean_series'], alpha=0.7)
            
            for cp in temporal['change_points']:
                ax1.axvline(x=cp, color='red', linestyle='--', alpha=0.5)
            
            ax1.set_title('S√©rie Temporal - M√©dia dos Sorteios')
            ax1.set_xlabel('Concurso')
            ax1.set_ylabel('M√©dia')
        
        # 2. Autocorrela√ß√£o
        ax2 = axes[0, 1]
        if 'temporal' in self.analysis_results:
            # Recalcular autocorrela√ß√£o para visualiza√ß√£o
            time_series = np.array(temporal['mean_series'])
            autocorr = signal.correlate(time_series, time_series, mode='full')
            autocorr = autocorr[len(autocorr)//2:][:200]  # Primeiros 200 lags
            autocorr /= autocorr[0]
            
            ax2.plot(autocorr)
            ax2.set_title('Fun√ß√£o de Autocorrela√ß√£o')
            ax2.set_xlabel('Lag')
            ax2.set_ylabel('Correla√ß√£o')
            ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)
        
        # 3. Matriz de transi√ß√£o (heatmap parcial)
        ax3 = axes[1, 0]
        if 'transitions' in self.analysis_results:
            matrix = np.array(self.analysis_results['transitions']['matrix'])
            # Mostrar apenas primeiros 20x20
            im = ax3.imshow(matrix[:20, :20], cmap='hot', aspect='auto')
            ax3.set_title('Matriz de Transi√ß√£o (20x20)')
            ax3.set_xlabel('N√∫mero Seguinte')
            ax3.set_ylabel('N√∫mero Atual')
            plt.colorbar(im, ax=ax3)
        
        # 4. Distribui√ß√£o de correla√ß√µes
        ax4 = axes[1, 1]
        correlations = []
        for i in range(len(self.engine.historical_data) - 1):
            draw1 = self.engine.historical_data[i]['numbers']
            draw2 = self.engine.historical_data[i + 1]['numbers']
            corr = self.engine.calculate_correlation(draw1, draw2)
            correlations.append(corr)
        
        ax4.hist(correlations, bins=50, alpha=0.7, density=True)
        ax4.axvline(x=0.754, color='red', linestyle='--', 
                   label='Alvo: 0.754', linewidth=2)
        ax4.set_title('Distribui√ß√£o de Correla√ß√µes')
        ax4.set_xlabel('Correla√ß√£o')
        ax4.set_ylabel('Densidade')
        ax4.legend()
        
        plt.tight_layout()
        plt.savefig('../output/pattern_analysis.png', dpi=300)
        plt.close()
        
        print("   ‚úì Visualiza√ß√µes salvas em: output/pattern_analysis.png")

# Script de execu√ß√£o
if __name__ == "__main__":
    from seed_discovery_engine import SeedDiscoveryEngine
    
    print("üî¨ AN√ÅLISE AVAN√áADA DE PADR√ïES")
    print("="*60)
    
    # Inicializar engine
    engine = SeedDiscoveryEngine()
    
    # Carregar dados
    data_path = "../data/MegaSena3.xlsx"
    engine.load_megasena_data(data_path)
    
    # Inicializar analisador
    analyzer = AdvancedPatternAnalyzer(engine)
    
    # Executar an√°lises
    analyzer.analyze_temporal_patterns()
    analyzer.analyze_number_transitions()
    
    # Buscar seeds primeiro
    print("\nüîç Buscando seeds candidatos...")
    candidates = engine.search_seed_at_change_point(engine.CHANGE_POINTS[0])
    
    if candidates:
        # Encontrar assinatura
        signatures = analyzer.find_seed_signature(candidates)
        
        if signatures:
            # Gerar relat√≥rio para o melhor
            best = signatures[0]
            best_candidate = {
                'seed': best['seed'],
                'c': best['c'],
                'signature': best
            }
            analyzer.generate_validation_report(best_candidate)
    
    # Gerar visualiza√ß√µes
    analyzer.visualize_analysis()
    
    print("\n‚úÖ An√°lise completa!")